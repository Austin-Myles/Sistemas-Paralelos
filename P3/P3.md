# Práctica Nro. 3

**Programación con OpenMP**

1. El  programa  ejercicio1.c  inicializa  una  matriz  de  NxN  de  la  siguiente  manera:  A[i,j]=i*j,  para  todo i,j=0..N-1. Compile y ejecute. ¿Qué problemas tiene el programa? Corríjalo. 

    - En primer lugar el programa no posee verificación alguna relacionada a los parametros, durante la compilación no hay problemas pero esto cambia a la hora de ejecutar. Una vez ejecutamos nos encontraremos con un mensaje "Segmentation fault (core dumped)", esto significa que el programa intenta acceder a una sección de memoria a la que no le pertenece o no tiene garantizado el acceso. 
    - Despues se tuvo que arreglar la definición del 'pragma omp parallel for shared(A) private(i,j)' ya que como estaba definido este, solo se utilizaba en las columnas y no en la matriz entera, ya que se dio el acceso a la matriz de manera compartida pero en temas de sincronización con i y j no estaba bien definido.
    ```
        //Antes 
        for(i=0;i<N;i++){
            #pragma omp parallel for shared(A) private(i,j)     
            for(j=0;j<N;j++){
                A[i*N+j]=i*j;
            }
        }  
    ```
    ```
        //Despues
        #pragma omp parallel for shared(A) private(i,j)      
        for(i=0;i<N;i++){
            for(j=0;j<N;j++){
                A[i*N+j]=i*j;
            }
        }  
    ```

2. Analice  y  compile  el  programa  ejercicio2.c.  Ejecute  varias  veces  y  compare  los resultados de salida para diferente número de threads. ¿Cuál es el problema? ¿Se le ocurre una solución? Nota: al compilar, agregue el flag -lm

    - a. El problema aqui es que aunque declaremos los hilos ningun hilo va a tener designado una variable local donde almacenar el valor de la operación con 'x', todos van a actualizar simultaneamente la variable 'x' dejando un resultado incorrecto ademas de mostrar la falta de sincronización que hay en el código.
    Resultados con N = 100 y Threads = 1, 2, 4, 8, 16, 32 y 64.
        ```
        ./ejercicio2 100 1
        Resultado: 510210459035504933925729625523410286094669840384.000000

        ./ejercicio2 100 2
        Resultado: 510210459035504933925729625523410286094669840384.000000
        
        ./ejercicio2 100 4
        Resultado: 510210459035504933925729625523410286094669840384.000000
        
        ./ejercicio2 100 8
        Resultado: 4064657410624480856099367409724875576896552697856.000000
        
        ./ejercicio2 100 16
        Resultado: 58722587648864194740739562138800786937758089216.000000
        
        ./ejercicio2 100 32
        Resultado: 1572430729948719552135938699985764917851942027264.000000

        ./ejercicio2 100 64
        Resultado: 3130598077568891406601031449801189919481562923008.000000
        ```

    - b. Luego de analizar el programa y el problema ocurrido, se me ocurrio que la idea deberia ser que los hilos se sincronizen y que cada uno poseea una copia del valor de 'x' para que no se pisen todos a la hora de actualizar el valor de este.
    Al cambiar "#pragma omp parallel for" a "#pragma omp parallel for reduction(+:x)" cada hilo tendra una copia local de 'x' y una vez finaliza el for paralelo, todos los diferentes valores de 'x' de cada hilo se almacenaran en la variable 'x' declarada en el programa principal. 
    Resultados con N = 100 y Threads = 1, 2, 4, 8, 16, 32 y 64.
        ```
        ./ejercicio2 100 1
        Resultado: 510210459035504933925729625523410286094669840384.000000

        ./ejercicio2 100 2
        Resultado: 5005507836129220107436032.000000
        
        ./ejercicio2 100 4
        Resultado: 15721395975490.652344
        
        ./ejercicio2 100 8
        Resultado: 36982297.826089
        
        ./ejercicio2 100 16
        Resultado: 80007.488785
        
        ./ejercicio2 100 32
        Resultado: 5186.547749

        ./ejercicio2 100 64
        Resultado: 1798.917220
        ```

3. El programa matrices.c realiza la multiplicación de 2 matrices cuadradas de NxN (C=AxB). Utilizando la directiva parallel for paralelice de dos formas:  
    1. Repartiendo entre los threads el cálculo de las filas de C. Es decir, repartiendo el trabajo del primer for.  
        
    2. Repartiendo el cálculo de las columnas de cada fila de C. Es decir, repartiendo el trabajo del segundo for.

    Compare los tiempos de ambas soluciones variando el número de threads. 

    1.  Repartir Threads en el primer for.       
        ```
            Multiplicacion de matrices resultado correcto
            ./matricesA 100 1
            Tiempo en segundos 0.004114
            Multiplicacion de matrices resultado correcto
            
            ./matricesA 100 2
            Tiempo en segundos 0.003940
            Multiplicacion de matrices resultado correcto

            ./matricesA 100 4
            Tiempo en segundos 0.008865
            Multiplicacion de matrices resultado correcto
        ```
    2.  Repartir Threads en el segundo for.
        ```
            Multiplicacion de matrices resultado correcto
            ./matricesB 100 1
            Tiempo en segundos 0.020398
            Multiplicacion de matrices resultado correcto
            
            ./matricesB 100 2
            Tiempo en segundos 0.027463
            Multiplicacion de matrices resultado correcto

            ./matricesB 100 4
            Tiempo en segundos 0.034633
            Multiplicacion de matrices resultado correcto
        ```
4. El programa traspuesta.c calcula la transpuesta de una matriz triangular de NxN. Compile y ejecute para 4 threads comparándolo con el algoritmo secuencial. 
Si bien el programa computa correctamente la transpuesta, éste tiene un problema desde el punto de vista del rendimiento. Analice las salidas y describa de qué problema se trata.  
¿Qué cláusula se debe usar para corregir el problema? Describa brevemente la cláusula OpenMP que resuelve el problema y las opciones que tiene. Corrija el algoritmo y ejecute de nuevo comparando con los resultados anteriores.
    - Simplemente agregue en el constructor FOR la cláusula Scheduler con parametro Dynamic para que la división de bloques del chunk se asigne bajo demanda del hilo que quiera realizar la operación.

5. El programa mxm.c realiza 2 multiplicaciones de matrices de MxM (D=AxB  y  E=CxB).  Paralelizar utilizando sections de forma que cada una de las multiplicaciones se realice en una sección y almacenar el código paralelo como mxmSections.c. Compile y ejecute con 2 threads y luego con 4 threads, ¿se consigue mayor speedup al incrementar la cantidad de threads? ¿Por qué? 
    - Con N = 512.  
    Tiempo "secuencial" en segundos 1.131791  
    Tiempo paralelo sections con 2 threads 1.626286  
    Tiempo paralelo sections con 4 threads 1.578693  
          
        Speedup 2 threads 1.131791 / 1.626286 = 0.6959  
        Speedup 4 threads 1.131791 / 1.578693 = 0.7169 
        


    - Con N = 1024.  
    Tiempo "secuencial" en segundos 8.955458  
    Tiempo paralelo sections con 2 threads 12.975011  
    Tiempo paralelo sections con 4 threads 13.129881  

        Speedup 2 threads 8.955458 / 12.975011 = 0.6902  
        Speedup 4 threads 8.955458 / 13.129881 = 0.6820  

    - Con N = 2048.  
    Tiempo "secuencial" en segundos 71.532101  
    Tiempo paralelo sections con 2 threads 101.286793  
    Tiempo paralelo sections con 4 threads 105.512232
    
        Speedup 2 threads 71.532101 / 101.286793 = 0.7062  
        Speedup 4 threads 71.532101 / 105.512232 = 0.6779